{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                   56.000000\n",
       "Pregnancies                   2.000000\n",
       "Glucose                     135.000000\n",
       "BloodPressure                25.000000\n",
       "SkinThickness                 0.000000\n",
       "Insulin                       0.000000\n",
       "BMI                          15.334567\n",
       "DiabetesPedigreeFunction      0.354901\n",
       "Age                          37.000000\n",
       "Outcome                       0.000000\n",
       "Name: 56, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Generated_data')\n",
    "df.iloc[56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 56.        ,   2.        , 135.        ,  25.        ,\n",
       "         0.        ,   0.        ,  15.33456705,   0.3549013 ,\n",
       "        37.        ,   0.        ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.values\n",
    "df[56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[:,1:9]\n",
    "y = df[:,9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.        , 135.        ,  25.        ,   0.        ,\n",
       "         0.        ,  15.33456705,   0.3549013 ,  37.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 8), (200, 8), (800,), (200,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDRegressor:\n",
    "    \n",
    "    def __init__(self,learning_rate=0.0001,epochs=100):\n",
    "        \n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def fit(self,X_train,y_train):\n",
    "        # init your coefs\n",
    "        self.intercept_ = 0\n",
    "        self.coef_ = np.random.rand(X_train.shape[1])\n",
    "\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            for j in range(X_train.shape[0]):\n",
    "                idx = np.random.randint(0,X_train.shape[0])\n",
    "                \n",
    "                y_hat = np.dot(X_train[idx],self.coef_) + self.intercept_\n",
    "                \n",
    "                intercept_der = -2 * (y_train[idx] - y_hat)\n",
    "                self.intercept_ = self.intercept_ - (self.lr * intercept_der)\n",
    "                \n",
    "                coef_der = -2 * np.dot((y_train[idx] - y_hat),X_train[idx])\n",
    "                self.coef_ = self.coef_ - (self.lr * coef_der)\n",
    "        \n",
    "        print(self.intercept_,self.coef_)\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        return np.clip((np.dot(X_test,self.coef_) + self.intercept_),0,1)/100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDRegressor(learning_rate=0.0001,epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3803453825603766 [ 0.07243564  0.15133668 -0.00912413  0.02019326 -0.01074781  0.06364677\n",
      "  0.03271671 -0.00694386]\n",
      "The time taken is 0.41224026679992676\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "sgd.fit(X_train_scaled,y_train)\n",
    "print(\"The time taken is\",time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07243564,  0.15133668, -0.00912413,  0.02019326, -0.01074781,\n",
       "        0.06364677,  0.03271671, -0.00694386])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3803453825603766"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = sgd.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/ML_-assignment/model1.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bspecial-space-palm-tree-rqwvg676pr4hp579/workspaces/ML_-assignment/model1.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m accuracy_score(y_test,y_pred)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    222\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336.43702006373815"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_diabetes(return_X_y=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "       220.,  57.])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/utils/_array_api.py:245: RuntimeWarning: invalid value encountered in cast\n",
      "  return x.astype(dtype, copy=copy, casting=casting)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y_pred contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/ML_-assignment/model1.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bspecial-space-palm-tree-rqwvg676pr4hp579/workspaces/ML_-assignment/model1.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m accuracy_score(y_test,y_pred)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    222\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     84\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m     85\u001b[0m type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my_pred\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     88\u001b[0m y_type \u001b[39m=\u001b[39m {type_true, type_pred}\n\u001b[1;32m     89\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/multiclass.py:382\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    380\u001b[0m     data \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mdata \u001b[39mif\u001b[39;00m issparse(y) \u001b[39melse\u001b[39;00m y\n\u001b[1;32m    381\u001b[0m     \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39many(data \u001b[39m!=\u001b[39m xp\u001b[39m.\u001b[39mastype(data, \u001b[39mint\u001b[39m)):\n\u001b[0;32m--> 382\u001b[0m         _assert_all_finite(data, input_name\u001b[39m=\u001b[39;49minput_name)\n\u001b[1;32m    383\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcontinuous\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m suffix\n\u001b[1;32m    385\u001b[0m \u001b[39m# Check multiclass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    125\u001b[0m     X,\n\u001b[1;32m    126\u001b[0m     xp\u001b[39m=\u001b[39;49mxp,\n\u001b[1;32m    127\u001b[0m     allow_nan\u001b[39m=\u001b[39;49mallow_nan,\n\u001b[1;32m    128\u001b[0m     msg_dtype\u001b[39m=\u001b[39;49mmsg_dtype,\n\u001b[1;32m    129\u001b[0m     estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    130\u001b[0m     input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    131\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    157\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    160\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m     )\n\u001b[0;32m--> 173\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input y_pred contains NaN."
     ]
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "         0.01990749, -0.01764613],\n",
       "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "        -0.06833155, -0.09220405],\n",
       "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "         0.00286131, -0.02593034],\n",
       "       ...,\n",
       "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "        -0.04688253,  0.01549073],\n",
       "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "         0.04452873, -0.02593034],\n",
       "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "        -0.00422151,  0.00306441]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDRegressor:\n",
    "    \n",
    "    def __init__(self,learning_rate=0.01,epochs=100):\n",
    "        \n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def fit(self,X_train,y_train):\n",
    "        # init your coefs\n",
    "        self.intercept_ = 0\n",
    "        self.coef_ = np.ones(X_train.shape[1])\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            for j in range(X_train.shape[0]):\n",
    "                idx = np.random.randint(0,X_train.shape[0])\n",
    "                \n",
    "                y_hat = np.dot(X_train[idx],self.coef_) + self.intercept_\n",
    "                \n",
    "                intercept_der = -2 * (y_train[idx] - y_hat)\n",
    "                self.intercept_ = self.intercept_ - (self.lr * intercept_der)\n",
    "                \n",
    "                coef_der = -2 * np.dot((y_train[idx] - y_hat),X_train[idx])\n",
    "                self.coef_ = self.coef_ - (self.lr * coef_der)\n",
    "        \n",
    "        print(self.intercept_,self.coef_)\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        return np.dot(X_test,self.coef_) + self.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDRegressor(learning_rate=0.01,epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3491/1778098861.py:21: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  intercept_der = -2 * (y_train[idx] - y_hat)\n",
      "/tmp/ipykernel_3491/1778098861.py:24: RuntimeWarning: overflow encountered in multiply\n",
      "  coef_der = -2 * np.dot((y_train[idx] - y_hat),X_train[idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan [nan nan nan nan nan nan nan nan]\n",
      "The time taken is 0.4288468360900879\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "sgd.fit(X_train,y_train)\n",
    "print(\"The time taken is\",time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stochastic_gradient_descent(x,y, alpha, iterations):\n",
    "\n",
    "    costIteration = []  # For storing the cost function at each iteration\n",
    "    theta = np.ones((1,x.shape[1]))# Initializing thetas with 0s\n",
    "\n",
    "    m = y.size\n",
    "\n",
    "\n",
    "    for i in range(iterations):\n",
    "      index=np.random.randint(0,x.shape[1]-1)\n",
    "      x_sample=x[index,:]\n",
    "      y_sample=y[index]\n",
    "      h = x_sample.dot(theta.T)\n",
    "      diff=h-y_sample\n",
    "      theta = theta - alpha*(diff[0]*x_sample)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan nan nan nan nan nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11541/1864798115.py:15: RuntimeWarning: overflow encountered in multiply\n",
      "  theta = theta - alpha*(diff[0]*x_sample)\n",
      "/tmp/ipykernel_11541/1864798115.py:15: RuntimeWarning: invalid value encountered in subtract\n",
      "  theta = theta - alpha*(diff[0]*x_sample)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/ML_-assignment/model1.ipynb Cell 26\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bspecial-space-palm-tree-rqwvg676pr4hp579/workspaces/ML_-assignment/model1.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m prediction_t\u001b[39m=\u001b[39m[]\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bspecial-space-palm-tree-rqwvg676pr4hp579/workspaces/ML_-assignment/model1.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X_train)):\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bspecial-space-palm-tree-rqwvg676pr4hp579/workspaces/ML_-assignment/model1.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     prediction\u001b[39m=\u001b[39m\u001b[39mround\u001b[39;49m(np\u001b[39m.\u001b[39;49mclip(X_train[i,:]\u001b[39m.\u001b[39;49mdot(theta),\u001b[39m0\u001b[39;49m,\u001b[39m1\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bspecial-space-palm-tree-rqwvg676pr4hp579/workspaces/ML_-assignment/model1.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     prediction_t\u001b[39m.\u001b[39mappend(prediction)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bspecial-space-palm-tree-rqwvg676pr4hp579/workspaces/ML_-assignment/model1.ipynb#X34sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m ConfusionMatrixDisplay(confusion_matrix(y_train,prediction_t))\u001b[39m.\u001b[39mplot()\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "j=0.01\n",
    "k=800\n",
    "theta=Stochastic_gradient_descent(X_train, y_train, alpha=j, iterations=k)[0]\n",
    "print(theta)\n",
    "prediction_t=[]\n",
    "for i in range(len(X_train)):\n",
    "    prediction=round(np.clip(X_train[i,:].dot(theta),0,1))\n",
    "    prediction_t.append(prediction)\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_train,prediction_t)).plot()\n",
    "print(accuracy_score(y_train,prediction_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Read the data\n",
    "Synthetic_data = pd.read_csv(r\"Generated_data\")\n",
    "\n",
    "\n",
    "X1=Synthetic_data.iloc[:,1:9]\n",
    "for i in X1.columns:\n",
    "    X1[i]=(X1[i]-X1[i].mean())/X1[i].std()\n",
    "X1.insert(0, 'Ones', 1)\n",
    "\n",
    "X=X1.iloc[0:800,:]\n",
    "Y=Synthetic_data.iloc[0:800:,9:10]\n",
    "\n",
    "x_t=X1.iloc[800:,:]\n",
    "y_t=Synthetic_data.iloc[800:,9:10]\n",
    "#Y=Y.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.56686962  0.42104778 -0.36305198 -0.02647819 -0.19367761  0.44672147\n",
      "  0.09491242  0.13901375  0.37635351]\n",
      "[0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "0.505\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "def Stochastic_gradient_descent(x,y, alpha, iterations):\n",
    "\n",
    "    costIteration = []  # For storing the cost function at each iteration\n",
    "    theta = np.ones((1,x.shape[1]))# Initializing thetas with 0s\n",
    "\n",
    "    m = y.size\n",
    "\n",
    "\n",
    "    for i in range(iterations):\n",
    "      index=np.random.randint(0,x.shape[1]-1)\n",
    "      x_sample=x.loc[index,:]\n",
    "      y_sample=y.loc[index,:]\n",
    "      h = x_sample.dot(theta.T)\n",
    "      diff=h-y_sample.values\n",
    "      theta = theta - alpha*(diff[0]*x_sample.values)\n",
    "    return theta\n",
    "\n",
    "\n",
    "j=0.01\n",
    "k=800\n",
    "theta=Stochastic_gradient_descent(X, Y, alpha=j, iterations=k)[0]\n",
    "print(theta)\n",
    "prediction_t=[]\n",
    "\n",
    "for i in x_t.index:\n",
    "    prediction=round(np.clip(x_t.loc[i,:].dot(theta),0,1))\n",
    "    prediction_t.append(prediction)\n",
    "print(prediction_t)\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_t,prediction_t)).plot()\n",
    "print(accuracy_score(y_t,prediction_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier,Lasso, RidgeClassifier, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression = LogisticRegression()\n",
    "LogisticRegression.fit(X_train,y_train)\n",
    "y_pred = LogisticRegression.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RidgeClassifier = RidgeClassifier()\n",
    "RidgeClassifier.fit(X_train,y_train)\n",
    "y_pred = RidgeClassifier.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.415"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGDClassifier = SGDClassifier()\n",
    "SGDClassifier.fit(X_train,y_train)\n",
    "y_pred = SGDClassifier.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
